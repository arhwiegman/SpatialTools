{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Setup the environment\n",
    "https://joelmccune.com/anaconda-and-arcgis-pro/\n",
    "create a file named `enviroment.yml` containing the following text\n",
    "\n",
    "```\n",
    "# https://joelmccune.com/anaconda-and-arcgis-pro/\n",
    "name: arcgis\n",
    "\n",
    "channels:\n",
    "  - esri \n",
    "  - conda-forge\n",
    "  - defaults\n",
    "  \n",
    "dependencies:\n",
    "  - arcgis\n",
    "  - arcpy\n",
    "  - deep-learning-essentials\n",
    "  - cookiecutter\n",
    "  - nodejs\n",
    "  - python=3.7\n",
    "```\n",
    "\n",
    "open command prompt as administrator\n",
    "navigate to directory where environment.yml is saved\n",
    "\n",
    "```\n",
    "> conda env create -f [C:\\path\\to\\your\\]environment.yml\n",
    "> conda activate arcgis\n",
    "```\n",
    "\n",
    "updating the environment, edit the enviromnent.yml file then navigate to the directory and enter the following command in the terminal as administrator. \n",
    "\n",
    "```\n",
    "conda env update --prefix arcgis --file environment.yml  --prune\n",
    "```\n",
    "\n",
    "### Preprpcessing \n",
    "\n",
    "1. Union > Dissolve Drago 500yr floodplains\n",
    "2. Project Trueheart to Drago, \n",
    "3. Union Trueheart and Drago\n",
    "4. Dissolve Imperv > calculate field Imperv = 1, Feature to Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.backups', '.ipynb_checkpoints', '.pyHistory', 'AssignRandomPoints2KMLs.ipynb', 'backup.aprx', 'ImportLog', 'Index', 'LandCoverClassification_SamplingPlots.gdb', 'LandCoverClassification_SamplingPlots.lyrx', 'LandLandcov_ImpervSrfcs2016', 'Map1.pdf', 'Map1_CDL19.pdf', 'Map1_Imagery.pdf', 'Map_image.pdf', 'Map_wetland.pdf', 'New Notebook.ipynb', 'outputs', 'sites', 'temp', 'VSWI_Wetlands_Advisory_Layer', 'VSWI_Wetlands_Advisory_Layer.zip', 'VSWI_Wetlands_Class_Layer', 'VSWI_Wetlands_Class_Layer.zip', 'VTWetlands.aprx', 'VTWetlands.aprx.xml', 'VTWetlands.gdb', 'VTWetlands.tbx', 'VTWetlands_2021-03-04.aprx', 'Wetland_Restoration_Model_Site_Prioritization_Lake_Champlain_2017', 'Wetland_Restoration_Model_Site_Prioritization_Lake_Champlain_2017.zip']\n",
      "C:/Workspace/VTWetlands/VTWetlands\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/\n"
     ]
    }
   ],
   "source": [
    "# setup work space\n",
    "import arcpy\n",
    "import os\n",
    "import glob\n",
    "import tempfile\n",
    "# Set environment settings\n",
    "arcpy.env.workspace = \"C:/Workspace/VTWetlands/VTWetlands/\"\n",
    "wd = arcpy.env.workspace + \"/\"\n",
    "print(os.listdir(wd))\n",
    "print(arcpy.env.workspace)\n",
    "outfolder = arcpy.env.workspace + \"/outputs/\"\n",
    "print(outfolder)\n",
    "\n",
    "# random number generator and seed \n",
    "arcpy.env.randomGenerator = \"99 ACM599\"\n",
    "\n",
    "# set the number of cores to distribute processing to\n",
    "arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# output coordinate system\n",
    "template_SRS = r\"D:\\GeoData\\LandLandcov_BaseLC2016\\LandLandcov_BaseLC2016.tif\"\n",
    "spatial_ref = arcpy.Describe(template_SRS).spatialReference\n",
    "arcpy.env.outputCoordinateSystem = spatial_ref \n",
    "\n",
    "# global parameters\n",
    "nstudents = 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH: None\n",
      "PATH: C:\\ProgramData\\Anaconda3\\envs\\arcgis\\Library\\bin;C:\\PROGRAM FILES\\ARCGIS\\PRO\\BIN;C:\\ProgramData\\Anaconda3;C:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\Anaconda3\\Library\\usr\\bin;C:\\ProgramData\\Anaconda3\\Library\\bin;C:\\ProgramData\\Anaconda3\\Scripts;C:\\Program Files\\Microsoft MPI\\Bin;C:\\Rtools\\bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\iCLS;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\iCLS;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\MATLAB\\R2019a\\runtime\\win64;C:\\Program Files\\MATLAB\\R2019a\\bin;C:\\Program Files\\Git\\cmd;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\WINDOWS\\System32\\OpenSSH;C:\\GDAL;C:\\Program Files\\GDAL;C:\\Program Files\\TauDEM\\TauDEM5Exe;C:\\Program Files\\MATLAB\\MATLAB Runtime\\v92\\runtime\\win64;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Admin\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Admin\\AppData\\Local\\atom\\bin;C:\\Users\\Admin\\Anaconda3\\condabin;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Admin\\AppData\\Julia 1.4.1;C:\\Users\\Admin\\AppData\\Local\\Julia\\Julia-1.4.1\\bin;C:\\Users\\Admin\\AppData\\Local\\Pandoc;.;C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\Scripts;C:\\ProgramData\\Anaconda3\\envs\\arcgis;C:\\ProgramData\\Anaconda3\\envs\\arcgis\\Scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"PYTHONPATH:\", os.environ.get('PYTHONPATH'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# select roads and buildings\n",
    "# https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/select-layer-by-location.htm\n",
    "indata = \"C:\\\\Workspace\\\\VTWetlands\\\\VTWetlands\\\\LandLandcov_ImpervSrfcs2016\\\\LandLandcov_ImpervSrfcs2016.gdb\\\\Land_ImpervSrfcs2016_poly\"\n",
    "sql = 'Class <> 3' # not bare soil\n",
    "selected = arcpy.management.SelectLayerByAttribute(indata, 'SUBSET_SELECTION', 'Class <> 3')\n",
    "outfile = outfolder+\"roads_buildings.shp\"\n",
    "if os.path.exists(outfile):\n",
    "    print(\"file exists:\",outfile)\n",
    "else:\n",
    "    arcpy.CopyFeatures_management(selected, outfile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# buffer roads and buildings by 25 meters and dissolve\n",
    "#selected = arcpy.management.SelectLayerByAttribute(outfile, 'SUBSET_SELECTION', 'OBJECTID < 3')\n",
    "desc = arcpy.Describe(selected) #C:\\Workspace\\VTWetlands\\VTWetlands\\VTWetlands.gdb\n",
    "#dissolved = arcpy.management.Dissolve(selected, outfolder+\"roads_buildings_dissolved.shp\")\n",
    "#arcpy.CopyFeatures_management(selected, outfolder+\"roads_buildings.shp\")\n",
    "#arcpy.analysis.Buffer(outfolder+\"roads_buildings.shp\", outfolder+\"roads_buildings_dissolved_buffer25m.shp\", \"25 Meters\", dissolve_option=\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Workspace\\VTWetlands\\VTWetlands\\outputs\\RCCP_Floodplain_Clip.shp<h2>Messages</h2>Start Time: Sunday, March 7, 2021 2:08:36 PM<br/>Reading Features...<br/>Cracking Features...<br/>Assembling Features...<br/>Succeeded at Sunday, March 7, 2021 2:08:40 PM (Elapsed Time: 4.06 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\VTWetlands\\\\VTWetlands\\\\outputs\\\\RCCP_Floodplain_Clip.shp'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clip RCPP sites to \n",
    "infile = \"Wetland_Restoration_Model_Site_Prioritization_Lake_Champlain_2017/Wetland_Restoration_Model_Site_Prioritization_Lake_Champlain_2017.shp\"\n",
    "clipfile = r\"C:\\Workspace\\VTWetlands\\VTWetlands\\VTWetlands.gdb\\Floodplain_500yr_drago_Proje\"\n",
    "clipped = outfolder+\"RCCP_Floodplain_Clip.shp\"\n",
    "arcpy.analysis.Clip(infile, clipfile, clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Workspace/VTWetlands/VTWetlands/outputs/RCCP_Floodplain_Clip.shp\n"
     ]
    }
   ],
   "source": [
    "# dissolve polygons of constraining feature\n",
    "inpath = clipped\n",
    "print(inpath)\n",
    "outfeatures = \"Dissolved.shp\"\n",
    "outpath = outfolder + outfeatures\n",
    "# check if file exists and delete before running script\n",
    "\n",
    "if os.path.exists(outpath):\n",
    "    arcpy.management.Delete(outpath)\n",
    "if os.path.exists(inpath):\n",
    "    arcpy.Dissolve_management (inpath, outpath)\n",
    "else: \n",
    "    print(\"input file does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:/Workspace/VTWetlands/VTWetlands/outputs\\randompoints.shp<h2>Messages</h2>Start Time: Sunday, March 7, 2021 2:08:55 PM<br/>WARNING 000983: The specified number of points could not be created in all cases due to restrictions from the minimum allowed distance.<br/>Succeeded at Sunday, March 7, 2021 2:08:56 PM (Elapsed Time: 0.62 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:/Workspace/VTWetlands/VTWetlands/outputs\\\\randompoints.shp'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 1 random points inside each polygon\n",
    "outname = \"randompoints.shp\"\n",
    "npoints = nstudents * 10\n",
    "mindistance = 100\n",
    "test = os.path.exists(outfolder+outname)\n",
    "if test:\n",
    "    print(test)\n",
    "    arcpy.management.Delete(outfolder+outname)\n",
    "\n",
    "arcpy.management.CreateRandomPoints(out_path=outfolder, \n",
    "                                    out_name=outname, \n",
    "                                    constraining_feature_class=inpath,             \n",
    "                                    number_of_points_or_field=1, \n",
    "                                    minimum_allowed_distance= mindistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting  C:/Workspace/VTWetlands/VTWetlands/outputs/dissolved_randompoints.shp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:/Workspace/VTWetlands/VTWetlands/outputs\\dissolved_randompoints.shp<h2>Messages</h2>Start Time: Sunday, March 7, 2021 2:35:50 PM<br/>Adding Name to dissolved_randompoints...<br/>Succeeded at Sunday, March 7, 2021 2:35:50 PM (Elapsed Time: 0.11 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:/Workspace/VTWetlands/VTWetlands/outputs\\\\dissolved_randompoints.shp'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n random points inside one dissovled polygon\n",
    "outname = \"dissolved_randompoints.shp\"\n",
    "npoints = nstudents * 30\n",
    "if os.path.exists(outfolder+outname):\n",
    "    print(\"deleting \",outfolder+outname)\n",
    "    arcpy.management.Delete(outfolder+outname)\n",
    "    \n",
    "random = arcpy.management.CreateRandomPoints(out_path=outfolder, \n",
    "                                    out_name=outname, \n",
    "                                    constraining_feature_class=outpath,             \n",
    "                                    number_of_points_or_field=npoints, \n",
    "                                    minimum_allowed_distance= mindistance)\n",
    "\n",
    "codeblock = '''\n",
    "def concat(x):\n",
    "    return('r'+str(x))\n",
    "    '''\n",
    "expression = \"concat(!FID!)\"\n",
    "inTable = random\n",
    "fieldName = \"Name\"\n",
    "arcpy.management.CalculateField(inTable, fieldName, expression, \"PYTHON3\", \n",
    "                                codeblock)\n",
    "\n",
    "codeblock = '''\n",
    "def concat(x):\n",
    "    return('v'+str(x))\n",
    "    '''\n",
    "expression = \"concat(!FID!)\"\n",
    "inTable = random\n",
    "fieldName = \"Name\"\n",
    "arcpy.management.CalculateField(inTable, fieldName, expression, \"PYTHON3\", \n",
    "                                codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dissolved_randompoints_Layer32\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'arcpy.conversion' has no attribute 'LayerToGPX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "In  \u001b[0;34m[23]\u001b[0m:\nLine \u001b[0;34m9\u001b[0m:     arcpy.conversion.LayerToGPX(layer=\u001b[33m\"\u001b[39;49;00m\u001b[33mtemp/temp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'arcpy.conversion' has no attribute 'LayerToGPX'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# test kml tool\n",
    "inlayer = outfolder + \"dissolved_randompoints.shp\"\n",
    "selection = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=\"FID > 10 And FID <= 20\")\n",
    "arcpy.management.CopyFeatures(selection, \"temp/temp\")\n",
    "arcpy.management.Delete(selection)\n",
    "print(selection)\n",
    "arcpy.conversion.LayerToGPX(layer=\"temp/temp\",\n",
    "                            out_kmz_file=\"temp/temp\")\n",
    "arcpy.FeatureClassToShapefile(Input_Features, Output_Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FIDmin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "In  \u001b[0;34m[25]\u001b[0m:\nLine \u001b[0;34m10\u001b[0m:    FIDmax= npoints+ FIDmin\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FIDmin' is not defined\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# assign random points to students\n",
    "\n",
    "# change number of points per student\n",
    "start=1\n",
    "nstudents= 5\n",
    "stop= start + nstudents\n",
    "IDmin= 0\n",
    "k = 5\n",
    "npoints= 2 * k\n",
    "FIDmax= npoints+ FIDmin\n",
    "y=int(npoints/2)\n",
    "col=\"FID\"\n",
    "inlayer = outfolder + \"dissolved_randompoints.shp\"\n",
    "#inlayer = r\"C:\\Workspace\\VTWetlands\\VTWetlands\\LandCoverClassification_SamplingPlots.gdb\\Placemarks\\Points\"\n",
    "files = [None]*nstudents\n",
    "print(files)\n",
    "for x in range(start, stop): #for loop\n",
    "    print(\"student\", x)\n",
    "    IDmin=y+IDmin\n",
    "    if x==start :\n",
    "        IDmin=0 #for the first student FIDmin=0\n",
    "    IDmax=IDmin+npoints\n",
    "    strIDmin=str(IDmin)\n",
    "    strIDmax=str(IDmax) #converting from int to str \n",
    "    print(IDmin, IDmax)\n",
    "    sql=col+\" > \" +strIDmin+\"  And \"+col+\" <= \"+strIDmax\n",
    "\n",
    "    if x==nstudents : #for the last student wrap to the first student\n",
    "        IDmax= IDmin + y\n",
    "        sqllow=col+\" > \" +\"0\"+\"  And \"+col+\" <= \"+str(y)\n",
    "        sqlhigh=\" OR \"+col+\" > \" +strIDmin+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "        sql=sqllow + sqlhigh\n",
    "    print(sql)\n",
    "    # select by attribute \n",
    "    selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "    #files[x-start] = arcpy.management.CopyFeatures(selected, \"temp/randompoints_\"+str(x))\n",
    "    #arcpy.DeleteFeatures_management(selected)\n",
    "    arcpy.conversion.LayerToKML(layer=selected,\n",
    "                                out_kmz_file=outfolder + \"kmls/randompoints_\"+str(x)+\".kmz\")\n",
    "    arcpy.management.Delete(selected)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      sralger\n",
      "1     bbalpard\n",
      "2     nebingha\n",
      "3     sbradle2\n",
      "4     lbrown28\n",
      "        ...   \n",
      "64    cwalther\n",
      "65       rwatt\n",
      "66      emwong\n",
      "67      szigic\n",
      "68    mczimmer\n",
      "Name: NETID, Length: 69, dtype: object\n",
      "    IDN      ID        lat        lon  sample_date        project\n",
      "0     1   MuF.1  44.566992 -73.158673   20180606.0  SurfPlots2018\n",
      "1     2  ThMB.1  43.968930 -73.154875   20180614.0  SurfPlots2018\n",
      "2     3   PoW.1  43.744040 -73.054515   20180621.0  SurfPlots2018\n",
      "3     4    Go.1  43.947220 -73.163715   20180625.0  SurfPlots2018\n",
      "4     5    Ro.1  43.655005 -73.066960   20180628.0  SurfPlots2018\n",
      "..  ...     ...        ...        ...          ...            ...\n",
      "67   68  LPG.FN  44.315099 -73.093247          NaN        FFI2021\n",
      "68   69   LPG.R  44.311853 -73.096554          NaN        FFI2021\n",
      "69   70   LP.AS  44.315051 -73.101600          NaN        FFI2021\n",
      "70   71   LP.RN  44.323403 -73.106364          NaN        FFI2021\n",
      "71   72   LP.RN  44.322274 -73.107976          NaN        FFI2021\n",
      "\n",
      "[72 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2021-03-05 working \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from arcgis.geometry import Geometry\n",
    "import math\n",
    "\n",
    "\n",
    "# read in list of selected sites and shuffle values\n",
    "df = pd.read_csv(wd+\"sites/selected_sites_2021-03-04.csv\")\n",
    "roster = pd.read_csv(wd+\"sites/roster.csv\")\n",
    "netid = roster.NETID\n",
    "print(netid)\n",
    "print(df)\n",
    "\n",
    "# create new field name for random points\n",
    "\n",
    "codeblock = '''\n",
    "def concat(x):\n",
    "    return('r'+str(x+1))\n",
    "    '''\n",
    "expression = \"concat(!FID!)\"\n",
    "random = outfolder + \"dissolved_randompoints.shp\"\n",
    "inTable = random\n",
    "fieldName = \"Name\"\n",
    "random = arcpy.management.CalculateField(inTable, fieldName, expression, \"PYTHON3\", \n",
    "                                codeblock)\n",
    "\n",
    "# create new field name for selected points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'IDN', 'ID', 'lat', 'lon', 'sample_dat', 'project', 'Name']\n"
     ]
    }
   ],
   "source": [
    "codeblock = '''\n",
    "def concat(x):\n",
    "    return('v'+str(x))\n",
    "    '''\n",
    "expression = \"concat(!IDN!)\"\n",
    "selected = wd+\"sites/mygeodata_csv_shp/selected_sites_2021-03-04-point.shp\"\n",
    "#newfeature = \"copy_selected_sites\"\n",
    "fieldName = \"Name\"\n",
    "selected = arcpy.management.CopyFeatures(in_features=selected,\n",
    "                                         out_feature_class=wd+\"VTWetlands.gdb/copy_selected_sites\")\n",
    "fieldList = arcpy.ListFields(selected)  #get a list of fields for each feature class\n",
    "print([fn.name  for fn in fieldList])\n",
    "\"\"\"for field in fieldList: #loop through each field\n",
    "    if field.name.lower() == 'name':  #look for the name elev\n",
    "        selected = arcpy.AlterField_management(selected, field.name, 'siteID')\"\"\"\n",
    "selected = arcpy.management.CalculateField(selected, fieldName, expression, \"PYTHON3\", \n",
    "                                codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3 ... 68 69 70 71]\n",
      "shuffled list\n",
      " [52 30 32 66 ...  6 46 29 33]\n",
      "iteration: 0\n",
      "IDmin_rand: 0\n",
      "IDmin_sample: 0\n",
      "index 0\n",
      "student sralger\n",
      "0 5\n",
      "FID > 0  And FID <= 5\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000210: Cannot create output C:/Workspace/VTWetlands/VTWetlands\\temp\\points_random0_sralger.shp\nFailed to execute (CopyFeatures).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[68]\u001b[0m:\nLine \u001b[0;34m23\u001b[0m:    IDmin_rand = random_selection1(inlayer,nstudents,IDmin_rand,z,npoints,col,netid,i)\n",
      "In  \u001b[0;34m[40]\u001b[0m:\nLine \u001b[0;34m27\u001b[0m:    files[x] = arcpy.management.CopyFeatures(selected, \u001b[33m\"\u001b[39;49;00m\u001b[33mtemp/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m+fname)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mCopyFeatures\u001b[0m:\nLine \u001b[0;34m3889\u001b[0m:  \u001b[34mraise\u001b[39;49;00m e\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m, in \u001b[0;32mCopyFeatures\u001b[0m:\nLine \u001b[0;34m3886\u001b[0m:  retval = convertArcObjectToPythonObject(gp.CopyFeatures_management(*gp_fixargs((in_features, out_feature_class, config_keyword, spatial_grid_1, spatial_grid_2, spatial_grid_3), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m511\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 000210: Cannot create output C:/Workspace/VTWetlands/VTWetlands\\temp\\points_random0_sralger.shp\nFailed to execute (CopyFeatures).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "IDmin_sample = 0\n",
    "IDmin_rand = 0\n",
    "\n",
    "# SELECTED\n",
    "start = 0\n",
    "stop = len(df.IDN)\n",
    "arr = np.arange(start,stop)\n",
    "print(arr)\n",
    "np.random.shuffle(arr)\n",
    "print('shuffled list\\n',arr)\n",
    "arr[1]\n",
    "\n",
    "for i in range(5):\n",
    "    # RANDOM\n",
    "    print (\"iteration:\",i)\n",
    "    print (\"IDmin_rand:\",IDmin_rand)\n",
    "    print (\"IDmin_sample:\",IDmin_sample)\n",
    "    inlayer = random\n",
    "    nstudents= len(roster[:3])\n",
    "    z = 1 # the proportion of nonoverlap, \n",
    "    npoints= 5\n",
    "    col = \"FID\"\n",
    "    IDmin_rand = random_selection1(inlayer,nstudents,IDmin_rand,z,npoints,col,netid,i)\n",
    "       \n",
    "    # SELECTED\n",
    "    inlayer = selected\n",
    "    np.random.shuffle(arr)\n",
    "    # parameters\n",
    "    nstudents= len(roster[:3])\n",
    "    z = 0.5 # the proportion of nonoverlap\n",
    "    npoints= 2\n",
    "    nstudentsperpoint = 9\n",
    "    col = \"FID\"\n",
    "    IDmin_sample = sample_selection2(inlayer,nstudents,IDmin_sample,z,npoints,col,netid,i,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection(inlayer,nstudents,IDmin,z,npoints,col,netid,i):\n",
    "    y = math.ceil(npoints*z)\n",
    "    IDmax= npoints+ IDmin\n",
    "    files = [None]*nstudents\n",
    "    for x in range(nstudents): #for loop\n",
    "        if x>0:\n",
    "            IDmin=y+IDmin\n",
    "            IDmax=IDmin+npoints\n",
    "        print(\"index\", x)\n",
    "        print(\"student\", netid[x])\n",
    "        print(IDmin, IDmax)\n",
    "        # set sql string\n",
    "        sql=col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "        \n",
    "        if x==nstudents : #for the last student wrap to the first student\n",
    "            IDmax= IDmin + y\n",
    "            sqllow=col+\" > \" +\"0\"+\"  And \"+col+\" <= \"+str(y)\n",
    "            sqlhigh=\" OR \"+col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "            sql=sqllow + sqlhigh\n",
    "        print(sql)\n",
    "        # select by attribute \n",
    "        \n",
    "        selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "        fname = \"points_random\"+str(i)+\"_\"+netid[x]\n",
    "        files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "        #arcpy.conversion.LayerToKML(layer=selected,\n",
    "        #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "        arcpy.management.Delete(selected)\n",
    "    return(IDmin)\n",
    "\n",
    "def sample_selection(inlayer,nstudents,IDmin,z,npoints,col,netid,i,arr):\n",
    "    IDmax= IDmin + npoints\n",
    "    files = [None]*nstudents\n",
    "    print(files)\n",
    "    for x in range(nstudents): #for loop\n",
    "        if x>0:\n",
    "            IDmin=y+IDmin\n",
    "            IDmax=IDmin+npoints\n",
    "        elif x==(nstudents-1):\n",
    "            IDmin = IDmax - y\n",
    "            \n",
    "        if x==(nstudents-1): #for the last student wrap to the first student\n",
    "            print(\"last student\")\n",
    "            rands = arr[0:y]\n",
    "            print(rands)\n",
    "            print(IDmin, IDmax)\n",
    "            sqllow=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "            rands = arr[int(IDmin):int(IDmax)]\n",
    "            sqlhigh=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "            sql=sqllow+\" OR \"+sqlhigh\n",
    "        else:\n",
    "            rands = arr[int(IDmin):int(IDmax)]\n",
    "            sql=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "        print(\"index\", x)\n",
    "        print(\"student\", netid[x])\n",
    "        print(IDmin, IDmax)\n",
    "        print(sql)\n",
    "        # select by attribute \n",
    "        selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "        fname = \"points_sample\"+str(i)+\"_\"+netid[x]\n",
    "        files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "        #arcpy.conversion.LayerToKML(layer=selected,\n",
    "        #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "        arcpy.management.Delete(selected)\n",
    "    return(IDmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection1(inlayer,nstudents,IDmin,z,npoints,col,netid,i):\n",
    "    y = math.ceil(npoints*z)\n",
    "    IDmax= npoints+ IDmin\n",
    "    files = [None]*nstudents\n",
    "    for x in range(nstudents): #for loop\n",
    "        if x>0:\n",
    "            IDmin=y+IDmin\n",
    "            IDmax=IDmin+npoints\n",
    "        print(\"index\", x)\n",
    "        print(\"student\", netid[x])\n",
    "        print(IDmin, IDmax)\n",
    "        # set sql string\n",
    "        sql=col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "        \n",
    "        if x==nstudents : #for the last student wrap to the first student\n",
    "            IDmax= IDmin + y\n",
    "            sqllow=col+\" > \" +\"0\"+\"  And \"+col+\" <= \"+str(y)\n",
    "            sqlhigh=\" OR \"+col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "            sql=sqllow + sqlhigh\n",
    "        print(sql)\n",
    "        # select by attribute \n",
    "        \n",
    "        selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "        fname = \"points_random\"+str(i)+\"_\"+netid[x]\n",
    "        files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "        #arcpy.conversion.LayerToKML(layer=selected,\n",
    "        #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "        arcpy.management.Delete(selected)\n",
    "    return(IDmin)\n",
    "\n",
    "def sample_selection2(inlayer,nstudents,IDmin,z,npoints,col,netid,i,arr):\n",
    "    IDmax= IDmin + npoints\n",
    "    files = [None]*nstudents\n",
    "    print(files)\n",
    "    for x in range(nstudents): #for loop\n",
    "        w = math.floor(x/9)\n",
    "        IDmin = IDmin+w\n",
    "        IDmax = IDmin+npoints\n",
    "        rands = arr[IDmin:IDmax]\n",
    "        sql = \" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "        print(\"index\", x)\n",
    "        print(\"student\", netid[x])\n",
    "        print(IDmin, IDmax)\n",
    "        print(sql)\n",
    "        # select by attribute \n",
    "        selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "        fname = \"points_sample\"+str(i)+\"_\"+netid[x]\n",
    "        files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "        #arcpy.conversion.LayerToKML(layer=selected,\n",
    "        #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "        arcpy.management.Delete(selected)\n",
    "    return(IDmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      sralger\n",
      "1     bbalpard\n",
      "2     nebingha\n",
      "3     sbradle2\n",
      "4     lbrown28\n",
      "        ...   \n",
      "64    cwalther\n",
      "65       rwatt\n",
      "66      emwong\n",
      "67      szigic\n",
      "68    mczimmer\n",
      "Name: NETID, Length: 69, dtype: object\n",
      "    IDN    name        lat        lon  sample_date        project\n",
      "0     1   MuF.1  44.566992 -73.158673   20180606.0  SurfPlots2018\n",
      "1     2  ThMB.1  43.968930 -73.154875   20180614.0  SurfPlots2018\n",
      "2     3   PoW.1  43.744040 -73.054515   20180621.0  SurfPlots2018\n",
      "3     4    Go.1  43.947220 -73.163715   20180625.0  SurfPlots2018\n",
      "4     5    Ro.1  43.655005 -73.066960   20180628.0  SurfPlots2018\n",
      "..  ...     ...        ...        ...          ...            ...\n",
      "67   68  LPG.FN  44.315099 -73.093247          NaN        FFI2021\n",
      "68   69   LPG.R  44.311853 -73.096554          NaN        FFI2021\n",
      "69   70   LP.AS  44.315051 -73.101600          NaN        FFI2021\n",
      "70   71   LP.RN  44.323403 -73.106364          NaN        FFI2021\n",
      "71   72   LP.RN  44.322274 -73.107976          NaN        FFI2021\n",
      "\n",
      "[72 rows x 6 columns]\n",
      "[ 0  1  2  3 ... 68 69 70 71]\n",
      "shuffled list\n",
      " [44 14 24  9 ... 19 63 52 51]\n",
      "index 0\n",
      "student sralger\n",
      "0 10\n",
      "FID > 0  And FID <= 10\n",
      "index 1\n",
      "student bbalpard\n",
      "9 19\n",
      "FID > 9  And FID <= 19\n",
      "index 2\n",
      "student nebingha\n",
      "18 28\n",
      "FID > 18  And FID <= 28\n",
      "[None, None, None]\n",
      "index 0\n",
      "student sralger\n",
      "0 3\n",
      "FID = 44 OR FID = 14 OR FID = 24\n",
      "index 1\n",
      "student bbalpard\n",
      "1 4\n",
      "FID = 14 OR FID = 24 OR FID = 9\n",
      "last student\n",
      "[44]\n",
      "2 5\n",
      "index 2\n",
      "student nebingha\n",
      "2 5\n",
      "FID = 44 OR FID = 24 OR FID = 9 OR FID = 41\n"
     ]
    }
   ],
   "source": [
    "# 2021-03-05 working \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from arcgis.geometry import Geometry\n",
    "import math\n",
    "\n",
    "df = pd.read_excel(wd+\"sites/selected_sites_2021-03-04.xlsx\")\n",
    "roster = pd.read_csv(wd+\"sites/roster.csv\")\n",
    "netid = roster.NETID\n",
    "print(netid)\n",
    "print(df)\n",
    "\n",
    "\n",
    "start = 0\n",
    "stop = len(df.IDN)\n",
    "arr = np.arange(start,stop)\n",
    "print(arr)\n",
    "np.random.shuffle(arr)\n",
    "print('shuffled list\\n',arr)\n",
    "arr[1]\n",
    "\n",
    "# change number of points per student\n",
    "inlayer = outfolder + \"dissolved_randompoints.shp\"\n",
    "nstudents= len(roster[:3])\n",
    "\n",
    "IDmin = 0\n",
    "z = .9 # the proportion of nonoverlap, \n",
    "npoints= 10\n",
    "y = math.ceil(npoints*z)\n",
    "IDmax= npoints+ IDmin\n",
    "col = \"FID\"\n",
    "files = [None]*nstudents\n",
    "for x in range(nstudents): #for loop\n",
    "    if x>0:\n",
    "        IDmin=y+IDmin\n",
    "        IDmax=IDmin+npoints\n",
    "    print(\"index\", x)\n",
    "    print(\"student\", netid[x])\n",
    "    print(IDmin, IDmax)\n",
    "    # set sql string\n",
    "    sql=col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "\n",
    "    if x==nstudents : #for the last student wrap to the first student\n",
    "        IDmax= IDmin + y\n",
    "        sqllow=col+\" > \" +\"0\"+\"  And \"+col+\" <= \"+str(y)\n",
    "        sqlhigh=\" OR \"+col+\" > \" +str(IDmin)+\"  And \"+col+\" <= \"+str(IDmax)\n",
    "        sql=sqllow + sqlhigh\n",
    "    print(sql)\n",
    "    # select by attribute \n",
    "      \n",
    "    selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "    fname = \"points_random_\"+netid[x]\n",
    "    files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "    #arcpy.conversion.LayerToKML(layer=selected,\n",
    "    #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "    arcpy.management.Delete(selected)\n",
    "    \n",
    "\n",
    "# change number of points per student\n",
    "inlayer = wd+\"sites/selected_sites_2021-03-04-point.shp\"\n",
    "\n",
    "# parameters\n",
    "nstudents= len(roster[:3])\n",
    "IDmin= 0\n",
    "\n",
    "z = 0.5 # the proportion of nonoverlap\n",
    "npoints= 2\n",
    "y = math.ceil(npoints*z)\n",
    "IDmax= IDmin + npoints\n",
    "col = \"FID\"\n",
    "files = [None]*nstudents\n",
    "print(files)\n",
    "for x in range(nstudents): #for loop\n",
    "    if x>0:\n",
    "        IDmin=y+IDmin\n",
    "        IDmax=IDmin+npoints\n",
    "    elif x==(nstudents-1):\n",
    "        IDmin = IDmax - y\n",
    "    if x==(nstudents-1): #for the last student wrap to the first student\n",
    "        print(\"last student\")\n",
    "        rands = arr[0:y]\n",
    "        print(rands)\n",
    "        print(IDmin, IDmax)\n",
    "        sqllow=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "        rands = arr[int(IDmin):int(IDmax)]\n",
    "        sqlhigh=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "        sql=sqllow+\" OR \"+sqlhigh\n",
    "    else:\n",
    "        rands = arr[int(IDmin):int(IDmax)]\n",
    "        sql=\" OR \".join([\"%s = %s\" % (col,str(r)) for r in rands])\n",
    "    print(\"index\", x)\n",
    "    print(\"student\", netid[x])\n",
    "    print(IDmin, IDmax)\n",
    "    print(sql)\n",
    "    # select by attribute \n",
    "    selected = arcpy.management.SelectLayerByAttribute(in_layer_or_view=inlayer,\n",
    "                                        selection_type=\"SUBSET_SELECTION\", \n",
    "                                        where_clause=sql)\n",
    "    fname = \"points_sample_\"+netid[x]\n",
    "    files[x] = arcpy.management.CopyFeatures(selected, \"temp/\"+fname)\n",
    "    #arcpy.conversion.LayerToKML(layer=selected,\n",
    "    #                            out_kmz_file=outfolder + \"kmls/\"+fname+\".kmz\")\n",
    "    arcpy.management.Delete(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['points_random0_sralger.shp', 'points_random1_sralger.shp', 'points_random_sralger.shp', 'points_sample0_sralger.shp', 'points_sample1_sralger.shp', 'points_sample_sralger.shp']\n"
     ]
    }
   ],
   "source": [
    "def globsearchinpath(inpath,globsearch):\n",
    "    os.chdir(inpath)\n",
    "    return(glob.glob(globsearch))\n",
    "x = 0\n",
    "\n",
    "outpath = wd + \"temp/\"\n",
    "files = globsearchinpath(outpath,\"points_*\"+netid[x]+\"*shp\")\n",
    "# Process:  Create a new empty feature class to append shapefiles to\n",
    "outname = netid[x]\n",
    "print(files)\n",
    "\n",
    "emptyFC = arcpy.CreateFeatureclass_management(outpath,\n",
    "                                              outname,\n",
    "                                              \"POINT\", \n",
    "                                              files[0])\n",
    "merge = arcpy.management.Merge(files,emptyFC, \"\", \"ADD_SOURCE_INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project data\n",
    "#indata = outfolder+\"randompoints.shp\"\n",
    "#spatial_ref = arcpy.Describe().spatialReference\n",
    "#arcpy.management.Project(indata, outfolder+\"prj_\"+\"randompoints.shp\", spatial_ref)\n",
    "\n",
    "# outfile names\n",
    "outnames = ['vtss_hygr',\n",
    "'lclu16_wet',\n",
    "'lclu16_shr',\n",
    "'lclu16_agr',\n",
    "'rcpp_score',\n",
    "'vswi_class',\n",
    "'vswi_advis']\n",
    "\n",
    "# value_fields\n",
    "invarnames = [\n",
    "    'HyGrNum',\n",
    "    'Class_name',\n",
    "    'Class_name',\n",
    "    'Class_name',\n",
    "    'RCPP_SCORE',\n",
    "    'CLASS',\n",
    "    'CLASS']\n",
    "\n",
    "pathnames = [r'D:\\GeoData\\VT_Data_-_NRCS_Soil_Survey_Units-shp\\VT_Data_-_NRCS_Soil_Survey_Units.shp',\n",
    "r'D:\\GeoData\\LandLandcov_Wetlands2016\\LandLandcov_Wetlands2016.gdb\\Land_Wetlands2016_poly',\n",
    "r'D:\\GeoData\\LandLandcov_Shrublands2016\\LandLandcov_Shrublands2016.gdb\\Land_Shrublands2016_poly',\n",
    "r'D:\\GeoData\\LandLandcov_Agriculture2016\\LandLandcov_Agriculture2016.gdb\\Land_Agriculture2016_poly',\n",
    "r'D:\\GeoData\\VSWI\\Wetland_Restoration_Model_Site_Prioritization__Lake_Champlain_2017_-shp\\Wetland_Restoration_Model_Site_Prioritization__Lake_Champlain_2017_.shp',\n",
    "r'D:\\GeoData\\VSWI\\VSWI_Wetlands_Class_Layer-shp\\VSWI_Wetlands_Class_Layer.shp',\n",
    "r'D:\\GeoData\\VSWI\\VSWI_Wetlands_Advisory_Layer-shp\\VSWI_Wetlands_Advisory_Layer.shp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/vtss_hygr.tif\n",
      "task complete True\n",
      "1\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/lclu16_wet.tif\n",
      "task complete True\n",
      "2\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/lclu16_shr.tif\n",
      "task complete True\n",
      "3\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/lclu16_agr.tif\n",
      "task complete True\n",
      "4\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/rcpp_score.tif\n",
      "task complete True\n",
      "5\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/vswi_class.tif\n",
      "task complete True\n",
      "6\n",
      "C:/Workspace/VTWetlands/VTWetlands/outputs/vswi_advis.tif\n",
      "task complete True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pathnames)):\n",
    "    print(i)\n",
    "    in_features=pathnames[i]\n",
    "    value_field=invarnames[i]\n",
    "    out_rasterdataset=outfolder+outnames[i]+\".tif\"\n",
    "    print(out_rasterdataset)\n",
    "    try:\n",
    "        arcpy.conversion.PolygonToRaster(in_features,\n",
    "                                     value_field,\n",
    "                                     out_rasterdataset)\n",
    "                                     #build_rat = \"BUILD\")\n",
    "        print(\"task complete\",os.path.exists(out_rasterdataset))\n",
    "    except:\n",
    "        print(\"task failed\\n outpath exists:\",os.path.exists(out_rasterdataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globsearchinpath(inpath,globsearch):\n",
    "    os.chdir(inpath)\n",
    "    return(glob.glob(globsearch))\n",
    "\n",
    "# extract values from list of rasters at points\n",
    "def arcpy_globExtractMultiValues2Points(inpath,globsearch,inpoints):\n",
    "    os.chdir(inpath)\n",
    "    inrasters = glob.glob(globsearch)\n",
    "    print(inrasters)\n",
    "    return(arcpy.sa.ExtractMultiValuesToPoints(inpoints,inrasters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inKML = 'C:\\Workspace\\VTWetlands\\VTWetlands\\sites\\LandCoverClassification_SamplingPlots.kmz'\n",
    "#arcpy.KMLToLayer_conversion(inKML, wd)\n",
    "#arcpy.management.Project(wd+'LandCoverClassification_SamplingPlots', outfolder+\"sites.shp\", spatial_ref)\n",
    "print(wd)\n",
    "inpoints = wd+'LandCoverClassification_SamplingPlots.gdb/Placemarks/Points'\n",
    "print(inpoints)\n",
    "table=arcpy_globExtractMultiValues2Points(inpath=\"D:/GeoData/Cropscape_VT\",\n",
    "                                    globsearch=\"*.tif\",\n",
    "                                    inpoints=inpoints)\n",
    "table=arcpy_globExtractMultiValues2Points(inpath='D:\\\\GeoData\\\\LandLandcov_BaseLC2016\\\\',\n",
    "                                    globsearch=\"*.tif\",\n",
    "                                    inpoints=inpoints)\n",
    "table=arcpy_globExtractMultiValues2Points(inpath=outfolder,\n",
    "                                    globsearch=\"*.tif\",\n",
    "                                    inpoints=inpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<string>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;34mC:\\ProgramData\\Anaconda3\\envs\\arcgis\\lib\\ast.py\u001b[0m, in \u001b[0;32mparse\u001b[0m:\nLine \u001b[0;34m35\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mcompile\u001b[39;49;00m(source, filename, mode, PyCF_ONLY_AST)\n",
      "\u001b[0;31mSyntaxError\u001b[0m: EOL while scanning string literal (<string>, line 4)\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "print(table)\n",
    "\n",
    "arcpy.conversion.TableToTable(table, \n",
    "                              out_path=r\"C:\\Workspace\\VTWetlands\\\",\n",
    "                              out_name=r\"extracted_sampling_plots.csv)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWhereClauseFromList(table, field, valueList):\n",
    "    \"\"\"Takes a list of values and constructs a SQL WHERE\n",
    "    clause to select those values within a given field and table.\"\"\"\n",
    "\n",
    "    # Add DBMS-specific field delimiters\n",
    "    fieldDelimited = arcpy.AddFieldDelimiters(arcpy.Describe(table).path, field)\n",
    "\n",
    "    # Determine field type\n",
    "    fieldType = arcpy.ListFields(table, field)[0].type\n",
    "\n",
    "    # Add single-quotes for string field values\n",
    "    if str(fieldType) == 'String':\n",
    "        valueList = [\"'%s'\" % value for value in valueList]\n",
    "\n",
    "    # Format WHERE clause in the form of an IN statement\n",
    "    whereClause = \"%s IN(%s)\" % (fieldDelimited, ', '.join(map(str, valueList)))\n",
    "    return whereClause\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
